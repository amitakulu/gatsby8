{"componentChunkName":"component---src-templates-blog-post-js","path":"/Blog/Roc/","result":{"data":{"markdownRemark":{"html":"<h3>What is the ROC Curve?<a href=\"#what-is-the-roc-curve-\" class=\"anchor\">ðŸ”—</a></h3>\n<ul>\n<li>\n<p><strong>True Positive Rate (Sensitivity)</strong>: This is on the Y-axis. It represents the proportion of actual positives that are correctly identified as such.</p>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mtext>Sensitivity</mtext><mo>=</mo><mfrac><mtext>TrueÂ Positives</mtext><mtext>TrueÂ PositivesÂ +Â FalseÂ Negatives</mtext></mfrac></mrow><annotation encoding=\"application/x-tex\">\\text{Sensitivity} = \\frac{\\text{True Positives}}{\\text{True Positives + False Negatives}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8778em;vertical-align:-0.1944em;\"></span><span class=\"mord text\"><span class=\"mord\">Sensitivity</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.3534em;vertical-align:-0.4811em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8723em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord text mtight\"><span class=\"mord mtight\">TrueÂ PositivesÂ +Â FalseÂ Negatives</span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord text mtight\"><span class=\"mord mtight\">TrueÂ Positives</span></span></span></span></span></span><span class=\"vlist-s\">â€‹</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4811em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n</li>\n<li>\n<p><strong>False Positive Rate (1 - Specificity)</strong>: This is on the X-axis. It represents the proportion of actual negatives that are incorrectly identified as positives.</p>\n<p><span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mtext>1Â -Â Specificity</mtext><mo>=</mo><mfrac><mtext>FalseÂ Positives</mtext><mtext>FalseÂ PositivesÂ +Â TrueÂ Negatives</mtext></mfrac></mrow><annotation encoding=\"application/x-tex\">\\text{1 - Specificity} = \\frac{\\text{False Positives}}{\\text{False Positives + True Negatives}}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.8889em;vertical-align:-0.1944em;\"></span><span class=\"mord text\"><span class=\"mord\">1Â -Â Specificity</span></span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:1.3612em;vertical-align:-0.4811em;\"></span><span class=\"mord\"><span class=\"mopen nulldelimiter\"></span><span class=\"mfrac\"><span class=\"vlist-t vlist-t2\"><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.8801em;\"><span style=\"top:-2.655em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord text mtight\"><span class=\"mord mtight\">FalseÂ PositivesÂ +Â TrueÂ Negatives</span></span></span></span></span><span style=\"top:-3.23em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"frac-line\" style=\"border-bottom-width:0.04em;\"></span></span><span style=\"top:-3.394em;\"><span class=\"pstrut\" style=\"height:3em;\"></span><span class=\"sizing reset-size6 size3 mtight\"><span class=\"mord mtight\"><span class=\"mord text mtight\"><span class=\"mord mtight\">FalseÂ Positives</span></span></span></span></span></span><span class=\"vlist-s\">â€‹</span></span><span class=\"vlist-r\"><span class=\"vlist\" style=\"height:0.4811em;\"><span></span></span></span></span></span><span class=\"mclose nulldelimiter\"></span></span></span></span></span></span></p>\n</li>\n</ul>\n<p>As the threshold of the classifier changes (i.e., the point above which a sample is classified as positive), both these rates change, giving us a curve when plotted against each other.</p>\n<h3><strong>2. Why use the ROC Curve?</strong><a href=\"#2--why-use-the-roc-curve-\" class=\"anchor\">ðŸ”—</a></h3>\n<ol>\n<li><strong>Threshold Selection</strong>: By looking at the ROC curve, we can select a threshold that offers a balance between sensitivity and specificity based on the problem's requirements.</li>\n<li><strong>Comparing Models</strong>: An ideal model's ROC curve hugs the top left corner, indicating high sensitivity and low false positives. The area under the ROC curve (AUC) provides a scalar value to compare different models. An AUC of 0.5 denotes a poor model (no better than random guessing), while an AUC of 1.0 denotes an excellent model.</li>\n</ol>\n<h3><strong>3. Example</strong>:<a href=\"#3--example-\" class=\"anchor\">ðŸ”—</a></h3>\n<p>Imagine we have a binary classification model that predicts whether a patient has a disease based on certain diagnostic tests. The model outputs a probability score for each patient. To classify them as having the disease or not, we need to select a threshold.</p>\n<ul>\n<li>If we set the threshold very high (e.g., 0.95), only patients with a score higher than this are classified as having the disease. This means we'll have very few false positives, but we may also miss many actual cases (low sensitivity).</li>\n<li>If we set the threshold very low (e.g., 0.1), many patients will be classified as having the disease, increasing sensitivity but also increasing false positives.</li>\n</ul>\n<p>By plotting the ROC curve, we can visualize this trade-off and select an appropriate threshold. Moreover, we can compare our model's performance with other models by comparing the AUC values.</p>\n<hr>\n<p>A step-by-step approach using a numerical example to explain the ROC curve and its calculations.</p>\n<h3><strong>Step 1: Sample Data</strong><a href=\"#step-1--sample-data\" class=\"anchor\">ðŸ”—</a></h3>\n<p>Imagine we have a dataset where we want to predict if a person is sick (1) or not (0). We use a model that gives us the following predictions in terms of probabilities:</p>\n<table>\n<thead>\n<tr>\n<th>Person</th>\n<th>Actual</th>\n<th>Predicted Probability</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>A</td>\n<td>1</td>\n<td>0.8</td>\n</tr>\n<tr>\n<td>B</td>\n<td>0</td>\n<td>0.4</td>\n</tr>\n<tr>\n<td>C</td>\n<td>1</td>\n<td>0.7</td>\n</tr>\n<tr>\n<td>D</td>\n<td>1</td>\n<td>0.3</td>\n</tr>\n<tr>\n<td>E</td>\n<td>0</td>\n<td>0.2</td>\n</tr>\n</tbody>\n</table>\n<h3><strong>Step 2: Rank Predictions</strong><a href=\"#step-2--rank-predictions\" class=\"anchor\">ðŸ”—</a></h3>\n<p>We rank the predictions in descending order:</p>\n<table>\n<thead>\n<tr>\n<th>Person</th>\n<th>Actual</th>\n<th>Predicted Probability</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>A</td>\n<td>1</td>\n<td>0.8</td>\n</tr>\n<tr>\n<td>C</td>\n<td>1</td>\n<td>0.7</td>\n</tr>\n<tr>\n<td>B</td>\n<td>0</td>\n<td>0.4</td>\n</tr>\n<tr>\n<td>D</td>\n<td>1</td>\n<td>0.3</td>\n</tr>\n<tr>\n<td>E</td>\n<td>0</td>\n<td>0.2</td>\n</tr>\n</tbody>\n</table>\n<h3><strong>Step 3: Calculate TPR and FPR at each Threshold</strong><a href=\"#step-3--calculate-tpr-and-fpr-at-each-threshold\" class=\"anchor\">ðŸ”—</a></h3>\n<p>We'll start with a threshold of 1.0 and decrease it step by step:</p>\n<ul>\n<li>\n<p>Threshold = 1.0</p>\n<ul>\n<li>Predict all as 0</li>\n<li>TPR = 0/3 = 0</li>\n<li>FPR = 0/2 = 0</li>\n</ul>\n</li>\n<li>\n<p>Threshold = 0.8</p>\n<ul>\n<li>Predict A as 1, rest as 0</li>\n<li>TPR = 1/3 â‰ˆ 0.33</li>\n<li>FPR = 0/2 = 0</li>\n</ul>\n</li>\n<li>\n<p>Threshold = 0.7</p>\n<ul>\n<li>Predict A, C as 1, rest as 0</li>\n<li>TPR = 2/3 â‰ˆ 0.67</li>\n<li>FPR = 0/2 = 0</li>\n</ul>\n</li>\n<li>\n<p>Threshold = 0.4</p>\n<ul>\n<li>Predict A, C, B as 1, rest as 0</li>\n<li>TPR = 2/3 â‰ˆ 0.67</li>\n<li>FPR = 1/2 = 0.5</li>\n</ul>\n</li>\n<li>\n<p>Threshold = 0.3</p>\n<ul>\n<li>Predict A, C, B, D as 1, E as 0</li>\n<li>TPR = 3/3 = 1</li>\n<li>FPR = 1/2 = 0.5</li>\n</ul>\n</li>\n<li>\n<p>Threshold = 0.2</p>\n<ul>\n<li>Predict all as 1</li>\n<li>TPR = 3/3 = 1</li>\n<li>FPR = 2/2 = 1</li>\n</ul>\n</li>\n</ul>\n<h3><strong>Step 4: Plotting the ROC Curve</strong><a href=\"#step-4--plotting-the-roc-curve\" class=\"anchor\">ðŸ”—</a></h3>\n<p>Now, we can plot the ROC curve using the TPR and FPR values at each threshold. The curve starts at (0,0), and as we decrease the threshold, it will move upwards and to the right, ending at (1,1).</p>\n<h3><strong>Step 5: Interpretation</strong><a href=\"#step-5--interpretation\" class=\"anchor\">ðŸ”—</a></h3>\n<p>From the above calculations, it's evident that our model is quite good. At a threshold of 0.7, it correctly identifies 67% of sick people without misclassifying any healthy person.</p>\n<p>The Area Under the Curve (AUC) would be the area under this ROC curve. A perfect classifier would have an AUC of 1, while a random classifier would have an AUC of 0.5.</p>\n<hr>\n<h3>Sample ROC Curve:<a href=\"#sample-roc-curve-\" class=\"anchor\">ðŸ”—</a></h3>\n<div class=\"gatsby-highlight\" data-language=\"python\"><pre class=\"language-python\"><code class=\"language-python\"><span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>datasets <span class=\"token keyword\">import</span> make_classification\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>model_selection <span class=\"token keyword\">import</span> train_test_split\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>linear_model <span class=\"token keyword\">import</span> LogisticRegression\n<span class=\"token keyword\">from</span> sklearn<span class=\"token punctuation\">.</span>metrics <span class=\"token keyword\">import</span> roc_curve<span class=\"token punctuation\">,</span> auc\n\n<span class=\"token comment\"># Step 1: Generate a synthetic dataset</span>\nX<span class=\"token punctuation\">,</span> y <span class=\"token operator\">=</span> make_classification<span class=\"token punctuation\">(</span>n_samples<span class=\"token operator\">=</span><span class=\"token number\">1000</span><span class=\"token punctuation\">,</span> n_features<span class=\"token operator\">=</span><span class=\"token number\">20</span><span class=\"token punctuation\">,</span> n_classes<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> random_state<span class=\"token operator\">=</span><span class=\"token number\">42</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Step 2: Split the data into training and test sets</span>\nX_train<span class=\"token punctuation\">,</span> X_test<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">,</span> y_test <span class=\"token operator\">=</span> train_test_split<span class=\"token punctuation\">(</span>X<span class=\"token punctuation\">,</span> y<span class=\"token punctuation\">,</span> test_size<span class=\"token operator\">=</span><span class=\"token number\">0.5</span><span class=\"token punctuation\">,</span> random_state<span class=\"token operator\">=</span><span class=\"token number\">42</span><span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Step 3: Train a classifier</span>\nclf <span class=\"token operator\">=</span> LogisticRegression<span class=\"token punctuation\">(</span>random_state<span class=\"token operator\">=</span><span class=\"token number\">42</span><span class=\"token punctuation\">)</span>\nclf<span class=\"token punctuation\">.</span>fit<span class=\"token punctuation\">(</span>X_train<span class=\"token punctuation\">,</span> y_train<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Step 4: Predict probabilities</span>\ny_pred_prob <span class=\"token operator\">=</span> clf<span class=\"token punctuation\">.</span>predict_proba<span class=\"token punctuation\">(</span>X_test<span class=\"token punctuation\">)</span><span class=\"token punctuation\">[</span><span class=\"token punctuation\">:</span><span class=\"token punctuation\">,</span><span class=\"token number\">1</span><span class=\"token punctuation\">]</span>\n\n<span class=\"token comment\"># Step 5: Compute ROC curve and ROC area</span>\nfpr<span class=\"token punctuation\">,</span> tpr<span class=\"token punctuation\">,</span> thresholds <span class=\"token operator\">=</span> roc_curve<span class=\"token punctuation\">(</span>y_test<span class=\"token punctuation\">,</span> y_pred_prob<span class=\"token punctuation\">)</span>\nroc_auc <span class=\"token operator\">=</span> auc<span class=\"token punctuation\">(</span>fpr<span class=\"token punctuation\">,</span> tpr<span class=\"token punctuation\">)</span>\n\n<span class=\"token comment\"># Plotting the ROC curve</span>\nplt<span class=\"token punctuation\">.</span>figure<span class=\"token punctuation\">(</span>figsize<span class=\"token operator\">=</span><span class=\"token punctuation\">(</span><span class=\"token number\">8</span><span class=\"token punctuation\">,</span> <span class=\"token number\">6</span><span class=\"token punctuation\">)</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span>fpr<span class=\"token punctuation\">,</span> tpr<span class=\"token punctuation\">,</span> color<span class=\"token operator\">=</span><span class=\"token string\">'darkorange'</span><span class=\"token punctuation\">,</span> lw<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> label<span class=\"token operator\">=</span><span class=\"token string\">'ROC curve (area = %0.2f)'</span> <span class=\"token operator\">%</span> roc_auc<span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>plot<span class=\"token punctuation\">(</span><span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> <span class=\"token punctuation\">[</span><span class=\"token number\">0</span><span class=\"token punctuation\">,</span> <span class=\"token number\">1</span><span class=\"token punctuation\">]</span><span class=\"token punctuation\">,</span> color<span class=\"token operator\">=</span><span class=\"token string\">'navy'</span><span class=\"token punctuation\">,</span> lw<span class=\"token operator\">=</span><span class=\"token number\">2</span><span class=\"token punctuation\">,</span> linestyle<span class=\"token operator\">=</span><span class=\"token string\">'--'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>xlabel<span class=\"token punctuation\">(</span><span class=\"token string\">'False Positive Rate'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>ylabel<span class=\"token punctuation\">(</span><span class=\"token string\">'True Positive Rate'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>title<span class=\"token punctuation\">(</span><span class=\"token string\">'Receiver Operating Characteristic (ROC) Curve'</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>legend<span class=\"token punctuation\">(</span>loc<span class=\"token operator\">=</span><span class=\"token string\">\"lower right\"</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>grid<span class=\"token punctuation\">(</span><span class=\"token boolean\">True</span><span class=\"token punctuation\">)</span>\nplt<span class=\"token punctuation\">.</span>show<span class=\"token punctuation\">(</span><span class=\"token punctuation\">)</span>\n</code></pre></div>\n<hr>\n<p><span\n      class=\"gatsby-resp-image-wrapper\"\n      style=\"position: relative; display: block; margin-left: auto; margin-right: auto; max-width: 800px; \n                             width: 100%;\n                             margin-top: 16px;\n                             margin-bottom: 16px;\n                             \"\n    >\n      <span\n    class=\"gatsby-resp-image-background-image\"\n    style=\"padding-bottom: 79.5%; position: relative; bottom: 0; left: 0; background-image: url('data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAABQAAAAQCAYAAAAWGF8bAAAACXBIWXMAAB7CAAAewgFu0HU+AAACFUlEQVR42n1UCZLjIBDz/1852YxtfOEDzA3a6vYxSWV2qSI0TreQQFDhbDlnCCHQNM091nWN75rmHdpWoGkF6qaF6Hq0osef5zfkvEB0A4x1jFOllNB1HWiMMcJ7Dx8TQswIwcObDcEqRKfhrYLfF0TVIW4twtog6R5xraHGlusrQtVaM+DdzABoAdgRMD1gRsBOPC80Jo+SApADSvJY5Qa97SiloKKfeZ4ZsBSgqAZFd8jRo+SEQtsB8Mgx5ZRjXesSpLTwIfP8BuyEQKLEvUfRggFyLlyYc+JeSuZ9ppigt81Byp2/0Tyl4//KWgvnPFJwgG7ulcpJ44ovVlQ4zxZa+3uHWNmZV9FJNqJDsuvBEBerzAkHq0OStQHjqOF9OsE/86q+77Ebi2RmwC3nivmFZTkleiyLfWN+gb0qYUDyUtpqlByP8jP5kiilwb6H269X8W9xNQwDJjkjbe0BeIMVljhNO7yPJ1j5LyBLZttZh0y+yz9epFNcV/ciCbe0n8N4j5khuZuuUlIdUBIiS9yhlLsl/saE+nUor706DOrZf9Y4TNIihPS26odM/LvxXR7HCWbuscz7h4TXU7ykZ6+g1QqlNZRSdydPV7Tiuq5o2xZaHx/7fuDrSDGN5ARjDLZt47x9nbDME76+HjyXUvLrRHnVxYhemcsqIQR+Oagty4LH48FPGhU/n0/EmO68izkppf4XFeLid8ai5AYAAAAASUVORK5CYII='); background-size: cover; display: block;\"\n  ></span>\n  <picture>\n          <source\n              srcset=\"/gatsby8/static/76b785f6e42ab0cecd3d7dec54e82580/507e6/Roc-cureve-of-the-above-code.webp 200w,\n/gatsby8/static/76b785f6e42ab0cecd3d7dec54e82580/28a80/Roc-cureve-of-the-above-code.webp 400w,\n/gatsby8/static/76b785f6e42ab0cecd3d7dec54e82580/8d2ea/Roc-cureve-of-the-above-code.webp 800w,\n/gatsby8/static/76b785f6e42ab0cecd3d7dec54e82580/68fc1/Roc-cureve-of-the-above-code.webp 1200w,\n/gatsby8/static/76b785f6e42ab0cecd3d7dec54e82580/b8a29/Roc-cureve-of-the-above-code.webp 1387w\"\n              sizes=\"(max-width: 800px) 100vw, 800px\"\n              type=\"image/webp\"\n            />\n          <source\n            srcset=\"/gatsby8/static/76b785f6e42ab0cecd3d7dec54e82580/36ca5/Roc-cureve-of-the-above-code.png 200w,\n/gatsby8/static/76b785f6e42ab0cecd3d7dec54e82580/a3397/Roc-cureve-of-the-above-code.png 400w,\n/gatsby8/static/76b785f6e42ab0cecd3d7dec54e82580/a331c/Roc-cureve-of-the-above-code.png 800w,\n/gatsby8/static/76b785f6e42ab0cecd3d7dec54e82580/8537d/Roc-cureve-of-the-above-code.png 1200w,\n/gatsby8/static/76b785f6e42ab0cecd3d7dec54e82580/677cc/Roc-cureve-of-the-above-code.png 1387w\"\n            sizes=\"(max-width: 800px) 100vw, 800px\"\n            type=\"image/png\"\n          />\n          <img\n            class=\"gatsby-resp-image-image\"\n            src=\"/gatsby8/static/76b785f6e42ab0cecd3d7dec54e82580/a331c/Roc-cureve-of-the-above-code.png\"\n            alt=\"Roc cureve of the above code\"\n            title=\"Roc cureve of the above code\"\n            loading=\"lazy\"\n            decoding=\"async\"\n            style=\"width:100%;height:100%;margin:0;vertical-align:middle;position:absolute;top:0;left:0;\"\n          />\n        </picture>\n    </span></p>\n<hr>\n<h3>How To Use The ROC Curve:<a href=\"#how-to-use-the-roc-curve-\" class=\"anchor\">ðŸ”—</a></h3>\n<ol>\n<li>\n<p><strong>Train the Model</strong>: Start by training a classification model on your training data.</p>\n</li>\n<li>\n<p><strong>Predict Probabilities</strong>: Once the model is trained, use it to predict probabilities on your validation or test data. These probabilities represent the model's confidence that a given sample belongs to the positive class.</p>\n</li>\n<li>\n<p><strong>Draw the ROC Curve</strong>: With the true labels and the predicted probabilities, calculate the True Positive Rate (TPR) and False Positive Rate (FPR) for various thresholds and plot them against each other to get the ROC curve.</p>\n</li>\n<li>\n<p><strong>Calculate AUC</strong>: Measure the area under the ROC curve. This gives a scalar value that measures the overall performance of the model. A higher AUC indicates better model performance.</p>\n<ul>\n<li>If the AUC is not satisfactory, go back to step 1. You might want to:\n<ul>\n<li>Change the model architecture.</li>\n<li>Adjust hyperparameters.</li>\n<li>Use different features.</li>\n<li>Obtain more training data or use techniques like data augmentation.</li>\n</ul>\n</li>\n</ul>\n</li>\n<li>\n<p><strong>Choose the Best Threshold</strong>: The ROC curve itself doesn't directly tell you what threshold to use. Instead, it shows the trade-offs between TPR and FPR for various thresholds. Here's how you can select an optimal threshold:</p>\n</li>\n</ol>\n<ul>\n<li>\n<p><strong>Closest to Top-Left</strong>: One common method is to choose the threshold for the point on the ROC curve closest to the top-left corner. This point represents both high sensitivity and high specificity.</p>\n</li>\n<li>\n<p><strong>Youden's J statistic</strong>: This is a common method where you choose the threshold that maximizes <span class=\"math math-inline\"><span class=\"katex\"><span class=\"katex-mathml\"><math xmlns=\"http://www.w3.org/1998/Math/MathML\"><semantics><mrow><mi>J</mi><mo>=</mo><mtext>TPR</mtext><mo>âˆ’</mo><mtext>FPR</mtext></mrow><annotation encoding=\"application/x-tex\">J = \\text{TPR} - \\text{FPR}</annotation></semantics></math></span><span class=\"katex-html\" aria-hidden=\"true\"><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord mathnormal\" style=\"margin-right:0.09618em;\">J</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span><span class=\"mrel\">=</span><span class=\"mspace\" style=\"margin-right:0.2778em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.7667em;vertical-align:-0.0833em;\"></span><span class=\"mord text\"><span class=\"mord\">TPR</span></span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span><span class=\"mbin\">âˆ’</span><span class=\"mspace\" style=\"margin-right:0.2222em;\"></span></span><span class=\"base\"><span class=\"strut\" style=\"height:0.6833em;\"></span><span class=\"mord text\"><span class=\"mord\">FPR</span></span></span></span></span></span>. It provides a balance between sensitivity and specificity.</p>\n</li>\n<li>\n<p><strong>Cost-based Approach</strong>: If you know the costs associated with false positives and false negatives, you can choose a threshold that minimizes the total expected cost.</p>\n</li>\n<li>\n<p><strong>Problem-specific Requirements</strong>: Depending on your application, you might prioritize sensitivity over specificity or vice versa. For instance, in a medical test, you might want to prioritize sensitivity to ensure you don't miss any true positive cases, even if it means tolerating more false positives.</p>\n</li>\n</ul>\n<ol start=\"6\">\n<li><strong>Deployment</strong>: Now, with the chosen threshold, when the model predicts probabilities for new unseen data, you can classify each sample as positive if its probability exceeds the threshold, and negative otherwise.</li>\n</ol>\n<hr>","frontmatter":{"title":"Roc Curve","author":"Gaurav","time":"25/03/2017","summary":"ROC curve visualizes a classifier's performance across various thresholds, plotting true positive rate against false positive rate. ","article":"MatheMatics","image":{"childImageSharp":{"gatsbyImageData":{"layout":"constrained","placeholder":{"fallback":"data:image/jpeg;base64,/9j/2wBDABALDA4MChAODQ4SERATGCgaGBYWGDEjJR0oOjM9PDkzODdASFxOQERXRTc4UG1RV19iZ2hnPk1xeXBkeFxlZ2P/2wBDARESEhgVGC8aGi9jQjhCY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2NjY2P/wgARCAALABQDASIAAhEBAxEB/8QAGAAAAgMAAAAAAAAAAAAAAAAAAAQCAwX/xAAWAQEBAQAAAAAAAAAAAAAAAAACAAP/2gAMAwEAAhADEAAAAYXIs5wZ4z//xAAbEAACAgMBAAAAAAAAAAAAAAABAhExAAMSE//aAAgBAQABBQJZGMRyIhb2qPJr/8QAFREBAQAAAAAAAAAAAAAAAAAAABL/2gAIAQMBAT8BS//EABcRAQADAAAAAAAAAAAAAAAAAAABEiH/2gAIAQIBAT8BjV3/xAAaEAABBQEAAAAAAAAAAAAAAAAQAAEREkEx/9oACAEBAAY/Ak0d020f/8QAGxABAAICAwAAAAAAAAAAAAAAAQARITFBUZH/2gAIAQEAAT8hRZq1qHuPVFufIm00TB3E8p//2gAMAwEAAgADAAAAEGcf/8QAFhEBAQEAAAAAAAAAAAAAAAAAAQAh/9oACAEDAQE/EMJC3//EABcRAQEBAQAAAAAAAAAAAAAAAAEAESH/2gAIAQIBAT8Q0uwwwL//xAAbEAEAAwEAAwAAAAAAAAAAAAABABEhQTFhcf/aAAgBAQABPxC9UUAMvpHFTPkOK7dxPMnCK7YFn1yCqIKn/9k="},"images":{"fallback":{"src":"/gatsby8/static/bfb058dccafd7ffb7da3289cf25add79/4ebcd/9.jpg","srcSet":"/gatsby8/static/bfb058dccafd7ffb7da3289cf25add79/bc483/9.jpg 200w,\n/gatsby8/static/bfb058dccafd7ffb7da3289cf25add79/7f7de/9.jpg 400w,\n/gatsby8/static/bfb058dccafd7ffb7da3289cf25add79/4ebcd/9.jpg 800w,\n/gatsby8/static/bfb058dccafd7ffb7da3289cf25add79/59026/9.jpg 1600w","sizes":"(min-width: 800px) 800px, 100vw"},"sources":[{"srcSet":"/gatsby8/static/bfb058dccafd7ffb7da3289cf25add79/35535/9.webp 200w,\n/gatsby8/static/bfb058dccafd7ffb7da3289cf25add79/ff8a0/9.webp 400w,\n/gatsby8/static/bfb058dccafd7ffb7da3289cf25add79/e9972/9.webp 800w,\n/gatsby8/static/bfb058dccafd7ffb7da3289cf25add79/9b00e/9.webp 1600w","type":"image/webp","sizes":"(min-width: 800px) 800px, 100vw"}]},"width":800,"height":460}}}}}},"pageContext":{"slug":"/Blog/Roc/"}},"staticQueryHashes":[],"slicesMap":{}}